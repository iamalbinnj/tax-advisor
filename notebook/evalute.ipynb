{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting absl-py (from rouge-score)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: nltk in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from rouge-score) (3.9.1)\n",
      "Requirement already satisfied: numpy in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from rouge-score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from rouge-score) (1.17.0)\n",
      "Requirement already satisfied: click in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from nltk->rouge-score) (8.1.8)\n",
      "Requirement already satisfied: joblib in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from nltk->rouge-score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from nltk->rouge-score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from nltk->rouge-score) (4.67.1)\n",
      "Requirement already satisfied: colorama in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from click->nltk->rouge-score) (0.4.6)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (pyproject.toml): started\n",
      "  Building wheel for rouge-score (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=25026 sha256=c88203b01d2a21aa853cc05e2613c19b065f761a9b6fe2b28930854dd89e3bc7\n",
      "  Stored in directory: c:\\users\\tuf\\appdata\\local\\pip\\cache\\wheels\\85\\9d\\af\\01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: absl-py, rouge-score\n",
      "Successfully installed absl-py-2.1.0 rouge-score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [\n",
    "    {\n",
    "        \"query\": \"Can failing to submit an income tax return lead to prosecution?\",\n",
    "        \"solution\": \"Yes, failing to submit an income tax return can lead to prosecution under the Income Tax Act.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What are the income tax rules for a salaried employee having salary less than 10 lakhs?\",\n",
    "        \"solution\": \"Salaried employees earning less than 10 lakhs can avail of tax deductions under Sections 80C, 80D, and other applicable sections.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Can I claim tax benefits on two home loans for the same property?\",\n",
    "        \"solution\": \"Yes, you can claim tax benefits on both home loans, provided they meet the conditions specified under Section 24 and Section 80C of the Income Tax Act.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\project\\tax_advisor\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "e:\\project\\tax_advisor\\.venv\\Lib\\site-packages\\transformers\\quantizers\\auto.py:206: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n",
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Loading Mistral-7B-Instruct model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Paths from environment variables\n",
    "DATA_DIR = os.getenv(\"DATA_DIR\", \"E:/project/tax_advisor/data\")\n",
    "MODEL_DIR = os.getenv(\"MODEL_DIR\", \"E:/project/tax_advisor/model/local_model\")\n",
    "CHROMA_DB_DIR = os.getenv(\"CHROMA_DB_DIR\", \"E:/project/tax_advisor/model/chroma_db\")\n",
    "\n",
    "# âœ… Load and process documents\n",
    "def load_docs(directory):\n",
    "    loader = DirectoryLoader(directory)\n",
    "    return loader.load()\n",
    "\n",
    "docs = load_docs(DATA_DIR)\n",
    "\n",
    "def split_docs(doc, chunk_size=512, chunk_overlap=20):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    return text_splitter.split_documents(doc)\n",
    "\n",
    "docs = split_docs(docs)\n",
    "\n",
    "# âœ… Initialize embeddings and vector store\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectordb = Chroma.from_documents(docs, embeddings, persist_directory=CHROMA_DB_DIR, collection_metadata={\"hnsw:space\": \"cosine\"})\n",
    "new_db = Chroma(persist_directory=CHROMA_DB_DIR, embedding_function=embeddings)\n",
    "\n",
    "def get_similar_docs(query, k=1, score=False):\n",
    "    return new_db.similarity_search_with_score(query, k=k) if score else new_db.similarity_search(query, k=k)\n",
    "\n",
    "# âœ… Check if GPU is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# âœ… Use 8-bit quantization to speed up inference & reduce memory\n",
    "bnb_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "\n",
    "print(\"ðŸš€ Loading Mistral-7B-Instruct model...\")\n",
    "\n",
    "# âœ… Load model ONCE at startup & keep it in memory\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_DIR, quantization_config=bnb_config).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
    "\n",
    "# âœ… Optimized text generation pipeline\n",
    "text_generation_pipeline = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    temperature=0.2,\n",
    "    do_sample=True,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=False,  \n",
    "    max_new_tokens=512,  \n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"{context}\\n\\nProvide a clear and concise answer based on India's tax laws:\\n{question}\\n\\nAnswer (India-Specific):\"\n",
    ")\n",
    "\n",
    "\n",
    "chain = create_stuff_documents_chain(llm, prompt_template)\n",
    "\n",
    "def get_answer(query):\n",
    "    similar_docs = get_similar_docs(query)\n",
    "    answer = chain.invoke({\"context\": similar_docs, \"question\": query})\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_system(test_data):\n",
    "    predictions = []\n",
    "    references = []\n",
    "    bleu_scores = []\n",
    "    rouge_l_scores = []\n",
    "    \n",
    "    smooth = SmoothingFunction().method1  # Smoothing to avoid zero BLEU score\n",
    "    \n",
    "    for item in test_data:\n",
    "        query = item[\"query\"]\n",
    "        reference = item[\"solution\"]\n",
    "        \n",
    "        # Generate response using the RAG pipeline\n",
    "        generated_response = get_answer(query).strip()\n",
    "        predictions.append(generated_response)\n",
    "        references.append(reference)\n",
    "\n",
    "        print(f\"Query: {query}\")\n",
    "        print(f\"Generated Response: {generated_response}\")\n",
    "        print(f\"Reference: {reference}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # BLEU score\n",
    "        bleu = sentence_bleu([reference.split()], generated_response.split(), smoothing_function=smooth)\n",
    "        bleu_scores.append(bleu)\n",
    "\n",
    "        # ROUGE-L score\n",
    "        rouge = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "        rouge_l = rouge.score(reference, generated_response)[\"rougeL\"].fmeasure\n",
    "        rouge_l_scores.append(rouge_l)\n",
    "    \n",
    "    # Calculate relaxed accuracy using ROUGE-L\n",
    "    accuracy = np.mean([1 if score > 0.5 else 0 for score in rouge_l_scores])\n",
    "\n",
    "    avg_bleu_score = np.mean(bleu_scores)\n",
    "    avg_rouge_l_score = np.mean(rouge_l_scores)\n",
    "\n",
    "    return accuracy, avg_bleu_score, avg_rouge_l_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Can failing to submit an income tax return lead to prosecution?\n",
      "Generated Response: Yes, failing to submit an income tax return can lead to prosecution under certain circumstances as provided in section 276CC of the Income Tax Act, 1961. However, for initiating prosecution, the following conditions must be satisfied:\n",
      "\n",
      "1. The total tax payable after deducting TDS should exceed Rs 1 lakh in the relevant assessment year.\n",
      "2. The assessee has failed to furnish the return of income for three consecutive assessment years.\n",
      "3. The assessee has also failed to pay the advance tax due during these three years.\n",
      "4. The amount of unpaid advance tax should be less than Rs 10,000 during each of these three years.\n",
      "\n",
      "If all these conditions are met, then the Assessing Officer may initiate prosecution against the assessee under section 276CC of the IT Act, 1961. It is essential to note that failure to file returns alone does not attract criminal proceedings under this section. The conditions mentioned above must be fulfilled before any prosecution can be initiated.\n",
      "Reference: Yes, failing to submit an income tax return can lead to prosecution under the Income Tax Act.\n",
      "--------------------------------------------------\n",
      "Query: What are the income tax rules for a salaried employee having salary less than 10 lakhs?\n",
      "Generated Response: As per the current financial year (FY20-21), the income tax slab rates for a salaried individual with an annual income less than Rs. 10 lakhs are as follows:\n",
      "\n",
      "1. No income tax is payable if total income is below Rs. 2.5 lakhs.\n",
      "2. For income between Rs. 2.5 lakhs and Rs. 5 lakhs, the tax rate is 5%.\n",
      "3. For income between Rs. 5 lakhs and Rs. 7.5 lakhs, the tax rate is 20% (applicable after deducting Rs. 12,500).\n",
      "4. For income above Rs. 15 lakhs, the tax rate is 30% (applicable after deducting Rs. 12,500 + Rs. 62,500).\n",
      "\n",
      "However, it's essential to note that these tax rates are applicable only after claiming all eligible deductions and exemptions under Section 80C, 80CCD, 80D, etc., which can significantly reduce your tax liability.\n",
      "\n",
      "Therefore, to minimize taxes on a salary of less than Rs. 10 lakhs, you must claim all eligible deductions and exemptions while filing your income tax return (ITR).\n",
      "Reference: Salaried employees earning less than 10 lakhs can avail of tax deductions under Sections 80C, 80D, and other applicable sections.\n",
      "--------------------------------------------------\n",
      "Query: Can I claim tax benefits on two home loans for the same property?\n",
      "Generated Response: No, you cannot claim tax benefits on two home loans for the same property as per Section 24(b) of the Income Tax Act, 1961. If you have taken multiple loans for the same property, you can only claim tax benefits on one loan at a time. The benefit of deduction from interest paid can be claimed against the first loan sanctioned, and the subsequent loans will not qualify for this deduction. However, you may still be able to claim tax benefits on the principal repayment made towards the second loan under Section 80C. It is advisable to consult a tax expert or financial advisor for further clarification regarding your specific circumstances.\n",
      "Reference: Yes, you can claim tax benefits on both home loans, provided they meet the conditions specified under Section 24 and Section 80C of the Income Tax Act.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "accuracy, avg_bleu_score, avg_rouge_l_score = evaluate_system(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0000\n",
      "BLEU Score: 0.0455\n",
      "ROUGE-L Score: 0.1783\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"BLEU Score: {avg_bleu_score:.4f}\")\n",
    "print(f\"ROUGE-L Score: {avg_rouge_l_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = {\n",
    "    \"what will happen if i fail to fill itr\": \"Failure to file ITR may lead to penalties and prosecution.\",\n",
    "    \"is aadhar necessary for filing itr\": \"Aadhaar is mandatory for filing ITR in most cases unless exempted.\"\n",
    "}\n",
    "\n",
    "# Retrieved documents from your vector database (simulate retrieval)\n",
    "retrieved_docs = {\n",
    "    \"what will happen if i fail to fill itr\": [\n",
    "        \"Not filing ITR can attract penalties.\",\n",
    "        \"You may face legal consequences for not filing ITR.\"\n",
    "    ],\n",
    "    \"is aadhar necessary for filing itr\": [\n",
    "        \"Aadhaar is usually required to file ITR.\",\n",
    "        \"Without Aadhaar, ITR filing may not be possible.\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "mrr_list = []\n",
    "cosine_similarities = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query, correct_answer in ground_truth.items():\n",
    "    retrieved = retrieved_docs.get(query, [])\n",
    "    if not retrieved:\n",
    "        continue  # Skip if no retrieval\n",
    "    \n",
    "    # Convert text to embeddings\n",
    "    correct_embedding = embeddings.embed_query(correct_answer)\n",
    "    retrieved_embeddings = [embeddings.embed_query(doc) for doc in retrieved]\n",
    "    \n",
    "    # Compute Cosine Similarity\n",
    "    similarities = [np.dot(correct_embedding, emb) / (np.linalg.norm(correct_embedding) * np.linalg.norm(emb)) for emb in retrieved_embeddings]\n",
    "    cosine_similarities.append(np.mean(similarities))\n",
    "    \n",
    "    # Rank-based MRR calculation\n",
    "    sorted_indices = np.argsort(similarities)[::-1]  # Sort in descending order\n",
    "    for rank, idx in enumerate(sorted_indices, start=1):\n",
    "        if similarities[idx] > 0.75:  # Assume similarity > 0.75 as relevant\n",
    "            mrr_list.append(1 / rank)\n",
    "            break\n",
    "    else:\n",
    "        mrr_list.append(0)  # No relevant document found\n",
    "    \n",
    "    # Precision, Recall, F1-Score (Binary Relevance: similarity > 0.75 is relevant)\n",
    "    y_true = [1] * len(retrieved)  # Assume all retrieved should be relevant\n",
    "    y_pred = [1 if sim > 0.75 else 0 for sim in similarities]\n",
    "    \n",
    "    precision_list.append(precision_score(y_true, y_pred, zero_division=0))\n",
    "    recall_list.append(recall_score(y_true, y_pred, zero_division=0))\n",
    "    f1_list.append(f1_score(y_true, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1-Score: 1.0000\n",
      "MRR: 1.0000\n",
      "Cosine Similarity: 0.9122\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision: {np.mean(precision_list):.4f}\")\n",
    "print(f\"Recall: {np.mean(recall_list):.4f}\")\n",
    "print(f\"F1-Score: {np.mean(f1_list):.4f}\")\n",
    "print(f\"MRR: {np.mean(mrr_list):.4f}\")\n",
    "print(f\"Cosine Similarity: {np.mean(cosine_similarities):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
