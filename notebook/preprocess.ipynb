{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.11.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"Device:\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA GeForce GTX 1650 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should return True if GPU is available\n",
    "print(torch.cuda.device_count())  # Should return number of GPUs\n",
    "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Name: NVIDIA GeForce GTX 1650 Ti\n",
      "Total VRAM: 4.29 GB\n",
      "Allocated VRAM: 7.55 GB\n",
      "Cached VRAM: 7.56 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Total VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"Allocated VRAM: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
    "    print(f\"Cached VRAM: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"No GPU detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keybert\n",
      "  Downloading keybert-0.9.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: sentence-transformers in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from keybert) (1.26.4)\n",
      "Requirement already satisfied: rich>=10.4.0 in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from keybert) (13.9.4)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from keybert) (1.6.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from sentence-transformers) (4.49.0)\n",
      "Requirement already satisfied: tqdm in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from sentence-transformers) (2.5.1+cu121)\n",
      "Requirement already satisfied: scipy in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from sentence-transformers) (0.29.2)\n",
      "Requirement already satisfied: Pillow in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: filelock in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from rich>=10.4.0->keybert) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from rich>=10.4.0->keybert) (2.19.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from scikit-learn>=0.22.2->keybert) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from scikit-learn>=0.22.2->keybert) (3.5.0)\n",
      "Requirement already satisfied: networkx in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (76.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\project\\tax_advisor\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Downloading keybert-0.9.0-py3-none-any.whl (41 kB)\n",
      "Installing collected packages: keybert\n",
      "Successfully installed keybert-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install keybert sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "âœ… Keyword extraction completed. Updated files are saved in /data/new_json/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from keybert import KeyBERT\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Define paths\n",
    "DATA_PATH = \"../data/json\"\n",
    "NEW_DATA_PATH = \"../data/new_json\"\n",
    "\n",
    "# Auto-detect device (Prefer CUDA if available)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load MiniLM model for KeyBERT\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\").to(device)\n",
    "kw_model = KeyBERT(model)  # Initialize KeyBERT with MiniLM\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(NEW_DATA_PATH, exist_ok=True)\n",
    "\n",
    "def extract_keywords(query, solution, top_n=5):\n",
    "    \"\"\"Extract relevant keywords using KeyBERT\"\"\"\n",
    "    text = f\"{query} {solution}\"  # Combine query & solution\n",
    "\n",
    "    # Extract keywords & phrases\n",
    "    keywords = kw_model.extract_keywords(text, keyphrase_ngram_range=(1, 2), stop_words=\"english\", top_n=top_n)\n",
    "\n",
    "    # Return keywords as a list of words/phrases\n",
    "    return [kw[0] for kw in keywords]\n",
    "\n",
    "# Process each JSON file in /data/json/\n",
    "for filename in os.listdir(DATA_PATH):\n",
    "    if filename.endswith(\".json\"):\n",
    "        file_path = os.path.join(DATA_PATH, filename)\n",
    "\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)  # Expecting a list of dictionaries\n",
    "\n",
    "        if isinstance(data, list):  # Ensure it's a list\n",
    "            for entry in data:\n",
    "                query = entry.get(\"Query\", \"\")\n",
    "                solution = entry.get(\"Solution\", \"\")\n",
    "\n",
    "                if query and solution:\n",
    "                    entry[\"keywords\"] = extract_keywords(query, solution)\n",
    "\n",
    "        # Save updated JSON to new path\n",
    "        new_file_path = os.path.join(NEW_DATA_PATH, filename)\n",
    "        with open(new_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "\n",
    "print(\"âœ… Keyword extraction completed. Updated files are saved in /data/new_json/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
